{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d98779-8a50-44a1-9c4d-2541cb1983d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sys, os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l1,l2, L1L2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import keras\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import datasets, linear_model\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "import keras.backend as K\n",
    "import sklearn\n",
    "\n",
    "cur=\"h\"\n",
    "IMP_input =  \"data/\"+cur+\".txt\"\n",
    "\n",
    "def indices_to_one_hot(data,nb_classes):\n",
    "\t\n",
    "\ttargets = np.array(data).reshape(-1)\n",
    "\t\n",
    "\treturn np.eye(nb_classes)[targets]\n",
    "\n",
    "nb_classes = 4\n",
    "\n",
    "data = pd.read_csv(IMP_input, sep='\\t',header=0,na_values='nan')\n",
    "SNP = data[data.columns[4:]]\n",
    "SNP = SNP.apply(pd.to_numeric, errors='coerce')\n",
    "pheno = data[data.columns[1]] \n",
    "pheno = pheno.apply(pd.to_numeric, errors='coerce')\n",
    "folds = data[data.columns[0]] \n",
    "folds = folds.apply(pd.to_numeric, errors='coerce')\n",
    "arr = np.empty(shape=[SNP.shape[0],SNP.shape[1] , nb_classes])\n",
    "for i in range(0,SNP.shape[0]):\n",
    "    arr[i] = indices_to_one_hot(pd.to_numeric(SNP.iloc[i],downcast='signed'), nb_classes)\n",
    "\n",
    "def resnet(input):\n",
    "\n",
    "    inputs = Input(shape=(input.shape[1],nb_classes))\n",
    "\n",
    "\n",
    "    x = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(inputs)\n",
    "    x = Conv1D(10,20,padding='same',activation = 'linear', kernel_initializer = 'TruncatedNormal',kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.75)(x)\n",
    "    shortcut = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(inputs)\n",
    "    x = layers.add([shortcut,x])\n",
    "    x = Conv1D(10,4,padding='same',activation = 'linear',kernel_initializer = 'TruncatedNormal', kernel_regularizer=regularizers.l2(0.1),bias_regularizer = regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.75)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.75)(x)\n",
    "    outputs = Dense(1,activation = isru,bias_regularizer = regularizers.l2(0.01),kernel_initializer = 'TruncatedNormal',name = 'out')(x)\n",
    "    model = Model(inputs = inputs,outputs = outputs)\n",
    "    model.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=0.001),metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def compile_saliency_function(model):\n",
    "\n",
    "    inp = model.layers[0].input\n",
    "    outp = model.layers[10].output\n",
    "    max_outp = K.max(outp, axis=1)\n",
    "    saliency = K.gradients(K.sum(max_outp), inp)\n",
    "    return K.function([inp,K.learning_phase()], saliency)\n",
    "\n",
    "def show_images_plot(saliency,wald,outname):\n",
    "\n",
    "    plt.figure(figsize=(15, 8), facecolor='w')\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    x = np.median(saliency,axis=-1)\n",
    "    plt.plot(x,'b.')\n",
    "    line = sorted(x,reverse = True)[10]\n",
    "    plt.axhline(y = line,color='b', linestyle='--')\n",
    "    plt.ylabel('saliency value', fontdict=None, labelpad=None,fontsize=15)\n",
    "\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(wald,'r1')\n",
    "    line = sorted(wald,reverse = True)[10]\n",
    "    plt.axhline(y = line,color='r', linestyle='--')\n",
    "\n",
    "    plt.xlabel('SNPs', fontdict=None, labelpad=None,fontsize=15)\n",
    "    plt.ylabel('Wald', fontdict=None, labelpad=None,fontsize=15)\n",
    "\n",
    "    plt.savefig(outname)\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def get_saliency(testSNP,model):\n",
    "\t\n",
    "\tarray= np.array([testSNP])\n",
    "\tsaliency_fn = compile_saliency_function(model)\n",
    "\tsaliency_out = saliency_fn([[y for y in array][0],1])\n",
    "\tsaliency = saliency_out[0]\n",
    "\tsaliency = saliency[::-1].transpose(1, 0, 2)\n",
    "\toutput= np.abs(saliency).max(axis=-1)\n",
    "\t\n",
    "\treturn output\n",
    "\n",
    "a= 0.03  #height\n",
    "\n",
    "def isru(x):\n",
    "\treturn  x/(K.sqrt(1+a*K.square(x)))\n",
    "\t\n",
    "\t\n",
    "def model_train(test,val,train,testPheno,valPheno,trainPheno,model_save,weights_save):\n",
    "\t\n",
    "\tbatch_size = 250\n",
    "\tearlystop = 5\n",
    "\tepoch = 100\n",
    "\tearly_stopping = EarlyStopping(monitor='val_mae', patience=earlystop)\n",
    "\t\n",
    "\tmodel = resnet(train)\n",
    "\thistory = model.fit(train, trainPheno, batch_size=batch_size, epochs=epoch, validation_data=(val,valPheno),callbacks=[early_stopping],shuffle= True)\n",
    "\t\n",
    "\t#model.save(model_save)\n",
    "\t#model.save_weights(weights_save)\t\n",
    "\t\n",
    "\tpred = model.predict(test)\n",
    "\tpred.shape = (pred.shape[0],)\t\t\n",
    "\tcorr = pearsonr(pred,testPheno)[0]\n",
    "\t\n",
    "\treturn history,corr\n",
    "\n",
    "\n",
    "imp_SNP = arr\n",
    "PHENOTYPE = pheno\n",
    "\n",
    "testIdx = np.where(folds == 1)[0]\n",
    "valIdx = np.where(folds == 2)[0]\n",
    "trainIdx = np.intersect1d(np.where(folds != 1),np.where(folds != 2))\n",
    "trainSNP, trainPheno = imp_SNP[trainIdx], PHENOTYPE[trainIdx]\n",
    "valSNP, valPheno = imp_SNP[valIdx], PHENOTYPE[valIdx]\n",
    "testSNP, testPheno = imp_SNP[testIdx], PHENOTYPE[testIdx]\n",
    "\n",
    "history, corr = model_train(testSNP,valSNP,trainSNP,testPheno,valPheno,trainPheno,'model_IMP/model_'+str(i)+'.txt','model_IMP/model_weights'+str(i)+'.h5')\n",
    "# IMP_corr.append(float('%0.4f' % corr))\n",
    "\n",
    "# print (\"Average PCC (imputed) from 10-fold cross validation: \" + str(np.mean(corr)))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_history(history,cur):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    sv=cur+\".png\"\n",
    "    plt.savefig(sv,bbox_inches='tight')\n",
    "    plt.show()\n",
    "plot_history(history,cur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
